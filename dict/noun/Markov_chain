Definition: a Markov process for which the parameter is discrete time values
Synonyms: Markoff_chain, Markov_process, a, Markov, process, for, which, the, parameter, is, discrete, time, values
Category: noun.process
